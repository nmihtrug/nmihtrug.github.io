@INPROCEEDINGS{Trung_2024,
    author    = {Trung Minh Nguyen and Phuong-Nam Tran and Duc Ngoc Minh Dang},
    title     = {Enhancing Speech Emotion Recognition through Knowledge Distillation},
    booktitle = {2024 15th International Conference on Information and Communication Technology Convergence (ICTC) (ICTC 2024)},
    year      = {2024},
    pages     = {197--202},
    url       = {https://ictc.org/sites/ictc2024/media?key=site/ictc2024/abs/H1-9.pdf},
    preview   = {ICTC2024_SERKnowledgeDistillation.png},
    pdf       = {ICTC2024_SERKnowledgeDistillation.pdf},
    selected  = {true},
    abstract  = {The importance of Speech Emotion Recognition (SER) is growing across diverse applications, which has resulted in the development of multiple methodologies and models to improve SER performance. Nevertheless, some modern SER models require significant processing resources and exhibit poor performance, making them unsuitable for real-time applications. To address this, we propose a novel approach that leverages Knowledge Distillation (KD) to create lightweight student models derived from the 3M-SER architecture. Our method focuses on compressing the text embedding component by replacing BERTBASE with smaller variants while maintaining VGGish for audio embedding. Experiments conducted on the IEMOCAP dataset demonstrate that our student model, which reduces model size by up to 44.9%, achieves performance remarkably close to that of the teacher model while improving inference time by up to 40.2% when trained with KD. These results underscore the effectiveness of KD in creating efficient and accurate SER models suitable for resource-constrained environments and real-time applications. Our work contributes to the ongoing effort to make advanced SER technology more accessible and deployable in practical settings.},
}